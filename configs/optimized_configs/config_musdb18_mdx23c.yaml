audio:
  chunk_size: 261120
  dim_f: 4096
  dim_t: 256
  hop_length: 1024
  n_fft: 8192
  num_channels: 2
  sample_rate: 44100
  min_mean_abs: 0.001

model:
  act: gelu
  bottleneck_factor: 5
  growth: 224
  norm: InstanceNorm
  num_blocks_per_scale: 4
  num_channels: 48
  num_scales: 4
  num_subbands: 4
  scale:
  - 2
  - 2

training:
  batch_size: 7
  gradient_accumulation_steps: 1
  grad_clip: 0
  instruments:
  - vocals
  - bass
  - drums
  - other
  lr: 9.895019867581646e-05
  patience: 8
  reduce_factor: 0.3067220909070577
  target_instrument: null
  num_epochs: 1000
  num_steps: 1000
  augmentation: false # enable augmentations by audiomentations and pedalboard
  augmentation_type: simple1
  use_mp3_compress: false # Deprecated
  augmentation_mix: true # Mix several stems of the same type with some probability
  augmentation_loudness: true # randomly change loudness of each stem
  augmentation_loudness_type: 2 # Type 1 or 2
  augmentation_loudness_min: 0.58042979886586
  augmentation_loudness_max: 1.6273706114263216
  q: 0.95
  coarse_loss_clip: true
  ema_momentum: 0.9843434567317182
  optimizer: adamw
  other_fix: false # it's needed for checking on multisong dataset if other is actually instrumental

inference:
  batch_size: 1
  dim_t: 128
  num_overlap: 8